# -*- coding: utf-8 -*-
"""assignment ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SqSsfxjmdM8NpaZWIusnXvipVj4l3qNb

# Data Loading
"""

from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
import warnings
warnings.filterwarnings("ignore")

import pandas as pd

# Load data
with open('/content/loan_approval_dataset.json', 'r') as f:
    # Read JSON data
    json_data = f.read()

# Convert JSON data to DataFrame
data = pd.read_json(json_data)


# Save DataFrame as CSV
data.to_csv('/content/loan_approval_dataset.csv', index=False)

# Check the first few rows of the DataFrame
print(data.head())

df=pd.read_csv(r'/content/loan_approval_dataset.csv')
df.head()

df.shape

df.tail()

"""#  Data Exploration and Visualization

"""

df.isnull().sum()

df.dropna(inplace=True)

df.describe()

df['Income'].dtype

df['Risk_Flag'].value_counts()

df['Risk_Flag'].value_counts(normalize=True)

df['Risk_Flag'].value_counts().plot.bar()

df['Married/Single'].value_counts(normalize=True).plot.bar(title='Married/Single')
plt.show()
df['House_Ownership'].value_counts(normalize=True).plot.bar(title='House_Ownership')
plt.show()
df['Car_Ownership'].value_counts(normalize=True).plot.bar(title='Car_Ownership')
plt.show()

df['Experience'].value_counts(normalize=True).plot.bar( title='Experience')
plt.show()

sns.distplot(df['Income'])
plt.show()
df['Income'].plot.box(figsize=(16,5))
plt.show()

sns.distplot(df['Age'])
plt.show()
df['Age'].plot.box(figsize=(16,5))
plt.show()

summary_stats = df.describe(include='all')

# Visualizations
plt.figure(figsize=(12, 6))

# Income Distribution
plt.subplot(1, 1, 1)
sns.histplot(df['Income'], kde=True)
plt.title('Income Distribution')

# Age Distribution
plt.subplot(1, 1, 1)
sns.histplot(df['Age'], kde=True)
plt.title('Age Distribution')

# Experience Distribution
plt.subplot(1,1,1)
sns.histplot(df['Experience'], kde=True)
plt.title('Experience Distribution')

# Marital Status vs Risk Flag
plt.subplot(1, 1, 1)
sns.countplot(x='Married/Single', hue='Risk_Flag', data=df)
plt.title('Marital Status vs Risk Flag')

# House Ownership vs Risk Flag
plt.subplot(1, 1, 1)
sns.countplot(x='House_Ownership', hue='Risk_Flag', data=df)
plt.title('House Ownership vs Risk Flag')

# Car Ownership vs Risk Flag
plt.subplot(1,1,1)
sns.countplot(x='Car_Ownership', hue='Risk_Flag', data=df)
plt.title('Car Ownership vs Risk Flag')

# Profession vs Risk Flag
plt.subplot(1,1,1)
sns.countplot(y='Profession', hue='Risk_Flag', data=df)
plt.title('Profession vs Risk Flag')

# Current Job Years vs Risk Flag
plt.subplot(1,1,1)
sns.histplot(df[df['Risk_Flag'] == 0]['CURRENT_JOB_YRS'], color='blue', label='Low Risk', kde=True)
sns.histplot(df[df['Risk_Flag'] == 1]['CURRENT_JOB_YRS'], color='red', label='High Risk', kde=True)
plt.legend()
plt.title('Current Job Years vs Risk Flag')

# Current House Years vs Risk Flag
plt.subplot(1,1,1)
sns.histplot(df[df['Risk_Flag'] == 0]['CURRENT_HOUSE_YRS'], color='blue', label='Low Risk', kde=True)
sns.histplot(df[df['Risk_Flag'] == 1]['CURRENT_HOUSE_YRS'], color='red', label='High Risk', kde=True)
plt.legend()
plt.title('Current House Years vs Risk Flag')

plt.tight_layout()
plt.show()

Married=pd.crosstab(df['Married/Single'],df['Risk_Flag'])
Married.div(Married.sum(1).astype(float), axis=0).plot(kind="bar",stacked=True,figsize=(4,4))
plt.show()

Education=pd.crosstab(df['Profession'],df['Risk_Flag'])
Education.div(Education.sum(1).astype(float), axis=0).plot(kind="bar",stacked=True,figsize=(4,4))
plt.show()

# Risk Flag distribution across states
plt.subplot(1, 1, 1)
sns.countplot(y='STATE', hue='Risk_Flag', data=df, order=df['STATE'].value_counts().index)
plt.title('Risk Flag Distribution Across States')

df.groupby('Risk_Flag')['Income'].mean().plot.bar()

df['Income'].max()

df['Income'].min()

bins=[10310, 2500000, 5000000, 7500000, 9999938]
group=['Low','Average','High','Very high']
df['Income']=pd.cut(df['Income'],bins,labels=group)
Income_bin=pd.crosstab(df['Income'],df['Risk_Flag'])
Income_bin.div(Income_bin.sum(1).astype(float), axis=0).plot(kind="bar",stacked=True)
plt.xlabel('ApplicantIncome')
P=plt.ylabel('Percentage')

numerical_features = ['Age', 'Experience', 'CURRENT_JOB_YRS', 'CURRENT_HOUSE_YRS']
for feature in numerical_features:
    plt.figure(figsize=(10, 6))
    sns.histplot(df[feature], kde=True, bins=30)
    plt.title(f'Distribution of {feature}')
    plt.savefig(f'distribution_{feature}.png')
    plt.show()

"""# feature engineering"""

# Feature Engineering
df['Age_Experience_Ratio'] = df['Experience'] / df['Age']
df['Job_House_Stability'] = df['CURRENT_JOB_YRS'] / df['CURRENT_HOUSE_YRS']
df['Total_Years'] = df['CURRENT_JOB_YRS'] + df['CURRENT_HOUSE_YRS']

# Replace any infinities or NaNs resulting from division by zero
df.replace([np.inf, -np.inf], np.nan, inplace=True)
df.fillna(0, inplace=True)

# Display the new features
print(df[['Age_Experience_Ratio', 'Job_House_Stability', 'Total_Years']].head())

"""# model building.

"""

# Encoding categorical features
le = LabelEncoder()
for column in ['Married/Single', 'House_Ownership', 'Car_Ownership', 'Profession', 'CITY', 'STATE', 'Income']:
    df[column] = le.fit_transform(df[column])

# Splitting the data into training and testing sets
X = df.drop('Risk_Flag', axis=1)
y = df['Risk_Flag']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Data Preprocessing
def preprocess_data(df):
    # Encoding categorical features
    le = LabelEncoder()
    for column in ['Married/Single', 'House_Ownership', 'Car_Ownership', 'Profession', 'CITY', 'STATE']:
        df[column] = le.fit_transform(df[column])

    # Splitting the data into training and testing sets
    X = df.drop('Risk_Flag', axis=1)
    y = df['Risk_Flag']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Feature scaling
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    return X_train, X_test, y_train, y_test

# Define models
models = {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
    "Gradient Boosting": GradientBoostingClassifier()
}

results = {}
skf = StratifiedKFold(n_splits=5)

for model_name, model in models.items():
    cv_scores = cross_val_score(model, X_train, y_train, cv=skf, scoring='roc_auc')
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]

    results[model_name] = {
        "confusion_matrix": confusion_matrix(y_test, y_pred),
        "classification_report": classification_report(y_test, y_pred, output_dict=True),
        "roc_auc": roc_auc_score(y_test, y_proba),
        "accuracy": accuracy_score(y_test, y_pred),
        "cv_scores": cv_scores
    }

# Print model performance
for model_name, metrics in results.items():
    print(f"Model: {model_name}")
    print(f"Accuracy: {metrics['accuracy']:.2f}")
    print(f"ROC AUC: {metrics['roc_auc']:.2f}")
    print(f"Cross-validation AUC Scores: {metrics['cv_scores']}")
    print(f"Classification Report:\n{metrics['classification_report']}")
    print(f"Confusion Matrix:\n{metrics['confusion_matrix']}")
    print("\n")

# Get feature importance from Random Forest model
model = RandomForestClassifier()
model.fit(X_train, y_train)
importance = model.feature_importances_
feature_names = df.drop('Risk_Flag', axis=1).columns
feature_importance = pd.DataFrame({'Feature': feature_names, 'Importance': importance})
feature_importance = feature_importance.sort_values(by='Importance', ascending=False)
print(feature_importance)